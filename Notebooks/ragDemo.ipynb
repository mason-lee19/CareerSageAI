{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "from typing import List\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "import unicodedata\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBaseLoader():\n",
    "    def __init__(self,file_path,table_name):\n",
    "        self.file_path = file_path\n",
    "        self.table_name = table_name\n",
    "\n",
    "        self.conn = sqlite3.connect(self.file_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "\n",
    "    def load(self) -> pd.DataFrame:\n",
    "        query = f\"SELECT * FROM {self.table_name}\"\n",
    "        df = pd.read_sql_query(query, self.conn)\n",
    "\n",
    "        documents = []\n",
    "        for idx,row in df.iterrows():\n",
    "            content = row['jobDetails']\n",
    "            metadata = {\n",
    "                \"url\":row['jobLink'],\n",
    "                \"title\":row['jobTitle']\n",
    "            }\n",
    "            documents.append(Document(page_content=content,metadata=metadata))\n",
    "\n",
    "        return documents\n",
    "\n",
    "    \n",
    "\n",
    "dbLoader = DataBaseLoader('../data/db.db','job_data')\n",
    "documents = dbLoader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaEmbeddings(Embeddings):\n",
    "    def __init__(self,model=\"mxbai-embed-large\"):\n",
    "        self.model=model\n",
    "\n",
    "    def embed_documents(self,texts):\n",
    "        return [self.embed_query(text) for text in texts]\n",
    "    \n",
    "    def embed_query(self,text):\n",
    "        response = ollama.embeddings(model=self.model,prompt=text.replace(u'\\u00a0',u' '))\n",
    "        return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=200,chunk_overlap=10)\n",
    "texts=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\",\"\\n\",\" \",\"\"]\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To use ollama embeddings\n",
    "- Downloaded ollama locally https://github.com/ollama/ollama?tab=readme-ov-file\n",
    "- pulled model locally > ollama pull mxbai-embed-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()\n",
    "\n",
    "vector_store = FAISS.from_documents(texts,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "retriever = vector_store.as_retriever(search_type='mmr',search_kwargs={'k':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=21f38ec02c730eb6&bb=eMSLhjA9uv7WNxvHP6iyNhX9k1k5K5nU2ObTUPP9GTlopBrdguSKxTKxbehRmKYRCP03xIjftNxlAhVwSTda5JvvdDa8H1c7fraW7npBVBadRCVc_jTZcw%3D%3D&xkcb=SoDb67M36bD247Sg2h0MbzkdCdPP&fccid=66403b30a2c0d89c&vjs=3', 'title': 'Data Engineer (L5) - Games'}, page_content='in Python, or Scala/Java. You have a software engineering mindset and strive to write elegant, maintainable code. You may even be a software engineer with a focus or passion for data-driven solutions.Have strong SQL skills and knowledgeYou have excellent communication in sharing context to effectively collaborate with analytical partners, domain experts, and other consumers of your work, preferably in supporting an engineering or product function. We like to collaborate across teams, and so do'),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=25fc39674dc43d5e&bb=DGUfQVEJ0zRJcR3fZxzGnlHCVniLNORnl3NL-XTA4-i-jGsfT4xyvTsupoBS6hjUvqnXfYCDkzgAq2L78uwsdN4quFrWnXx-zPq9R2H4odjrRWSW3-kPGe1FMlmq7PGH&xkcb=SoDA67M36bD1-7wv6Z0FbzkdCdPP&fccid=4f46a80a0b4401fe&vjs=3', 'title': 'Staff Data Engineer'}, page_content='seeking a seasoned Staff data engineer to drive data platform initiatives across the data value chain at Karius. We develop and operate AI-driven data analytics pipelines to deliver life-saving results in the highly complex infectious disease landscape. In this role, you will have the opportunity to develop and optimize the data platform to enable our users to extract insights from large amounts of commercial, operational, genomic, and clinical data, ultimately providing actionable insights'),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=25fc39674dc43d5e&bb=DGUfQVEJ0zRJcR3fZxzGnlHCVniLNORnl3NL-XTA4-i-jGsfT4xyvTsupoBS6hjUvqnXfYCDkzgAq2L78uwsdN4quFrWnXx-zPq9R2H4odjrRWSW3-kPGe1FMlmq7PGH&xkcb=SoDA67M36bD1-7wv6Z0FbzkdCdPP&fccid=4f46a80a0b4401fe&vjs=3', 'title': 'Staff Data Engineer'}, page_content='scipy, plotly, seaborn, matplotlib, altair), and ML tooling (e.g. MLflow, SageMaker).Generative AI: Working knowledge of generative AI concepts and hands-on experience with frameworks and tooling (e.g. LangChain, LlamaIndex, OpenAPI, RAG, vector databases, agents, Bedrock).Data Governance and Compliance: Demonstrated experience in implementing and maintaining data governance and compliance frameworks, including handling Protected Health Information (PHI) and adhering to regulatory standards.'),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=cf8d5aed05e5ce6f&bb=eMSLhjA9uv7WNxvHP6iyNssDpPuZcw8r-eKg-VG5zry_yt_bq4yR_o7rlwS76moSYsOg148yzJj7v3Xk91nY2YPIIis7PZ9LgF_q4fLbJDrEc1ScCwHLtCI_-Z_KYmrU&xkcb=SoCV67M36bD247Sg2h0GbzkdCdPP&fccid=2df6a1e69a70a1e7&vjs=3', 'title': 'Data Engineer with Pyspark (Onsite)'}, page_content='data resources into informative, meaningful intelligence.Location: Mountainview, CA (Onsite)Job SummaryLooking for Data Engineer with Pyspark and AWS skillsResponsibilities1) Requirement understanding and gathering2) Design and develop data pipelines for new module3) Unit testing and help UAT team for any issues4) Upload all the deliverables in Git and help prod team to deploy the code in prodDesign and implement robust data transformation pipelines using pysparkDevelop and maintain a scalable'),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=2e6b992131585f28&bb=eMSLhjA9uv7WNxvHP6iyNgLU9-i8XlMubDUBcjD8ekIyfNs0csZY7bH9ajN7-IEODki2t7xDCyTj8XcpmwMpPKkNqYGGqZe0A175U9R2_-L-2Vl-Gm3fTg%3D%3D&xkcb=SoDy67M36bD247Sg2h0ObzkdCdPP&fccid=ba07516c418dda52&vjs=3', 'title': 'Data Analytics Engineer'}, page_content=\"large data sets while maximizing the performance of the workbook.Experience interpreting technical or dashboard structures and translating them to complex business requirements to technical specifications.Experience in building internal and external customer relationships.Experience with Agile and/or scrum project management techniques.  Preferred Qualifications:Master's degree in a STEM field.Experience with one or more of the following: data processing automation, data quality, data\"),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=95f7bd3fb1e18475&bb=eMSLhjA9uv7WNxvHP6iyNr9NKHG6y0o9LOP82MOgnezF6F9H-O-vsAXQNjEsIT5dYMgz356YiZroTlbo9GpNJsdu3xFZYnYa3wyOqJ5x6G_hAeqUgbXI_w%3D%3D&xkcb=SoAy67M36bD247Sg2h0DbzkdCdPP&fccid=1ba7f338730ce720&vjs=3', 'title': 'Data Engineer'}, page_content=\"and machine learningEnsure efficient use of Cloud Credits across projectsIdentify and assess potential data acquisitionsContribute to technical discussions at a big picture level and provide feedback on decisions and interpretations.Required Capabilities:PhD, Master's degree, or Bachelorâ€™s degree in Computer Science, Software Engineering, or a related field5+ years of experience in software development and big data engineeringStrong programming skills in Python and experience with relational\"),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=25fc39674dc43d5e&bb=DGUfQVEJ0zRJcR3fZxzGnlHCVniLNORnl3NL-XTA4-i-jGsfT4xyvTsupoBS6hjUvqnXfYCDkzgAq2L78uwsdN4quFrWnXx-zPq9R2H4odjrRWSW3-kPGe1FMlmq7PGH&xkcb=SoDA67M36bD1-7wv6Z0FbzkdCdPP&fccid=4f46a80a0b4401fe&vjs=3', 'title': 'Staff Data Engineer'}, page_content='You will get to see how much your work really matters.    Travel: No travel required    Physical Requirements    Subject to extended periods of sitting and/or standing, vision to monitor and moderate noise levels. Work is generally performed in an office environment.    Position Requirements    We are seeking a data engineer with exceptional system thinking. Critical to this role is the ability to grasp business needs, identify the complexity and interconnections of data elements, and determine'),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=e868f78be4ab79a7&bb=DGUfQVEJ0zRJcR3fZxzGniuUyEZKpcTKPqt5LBhMGmXsk3ygzWM3E83fPXs63uzWOiOd2yvMaPQz_ojCMhk7HAR7EZOlOuUS2GFND22pzSvoozbH5M7oD4vg2lY87F4a&xkcb=SoAA67M36bD1-7wv6Z0IbzkdCdPP&fccid=87c08f0984b02c4c&vjs=3', 'title': 'Scientist, Life Science Data Engineer'}, page_content='multiple projects simultaneously.Experience with experimental science and a healthy curiosity to learn more.Strong teamwork, communication, and presentation skills.  Bonus Qualifications: Data or Software Engineering role in Biology, Chemistry, or other Life Science industry.Life Science application experience (KNIME, Benchling).Web application development experience (Django, Flask, React).Proficient with visual analytic software (Power BI, Spotfire).Knowledge of Snowflake data engineering.  We'),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=21f38ec02c730eb6&bb=eMSLhjA9uv7WNxvHP6iyNhX9k1k5K5nU2ObTUPP9GTlopBrdguSKxTKxbehRmKYRCP03xIjftNxlAhVwSTda5JvvdDa8H1c7fraW7npBVBadRCVc_jTZcw%3D%3D&xkcb=SoDb67M36bD247Sg2h0MbzkdCdPP&fccid=66403b30a2c0d89c&vjs=3', 'title': 'Data Engineer (L5) - Games'}, page_content='team to develop and maintain key schemas for use by all games. Who You Are:7+ years in software development, with experience building systems that collect or process data for use in analytics products.Enjoy a high level of autonomy in managing cross-functional engineering projects. We value people over process.Have experience building production data pipelines using Spark, Flink or Hive/Hadoop. Have hands-on experience with schema design and data modeling.Have programming proficiency in Python,'),\n",
       " Document(metadata={'url': 'https://www.indeed.com/rc/clk?jk=25fc39674dc43d5e&bb=DGUfQVEJ0zRJcR3fZxzGnlHCVniLNORnl3NL-XTA4-i-jGsfT4xyvTsupoBS6hjUvqnXfYCDkzgAq2L78uwsdN4quFrWnXx-zPq9R2H4odjrRWSW3-kPGe1FMlmq7PGH&xkcb=SoDA67M36bD1-7wv6Z0FbzkdCdPP&fccid=4f46a80a0b4401fe&vjs=3', 'title': 'Staff Data Engineer'}, page_content='- Batch and Stream Processing: Experience in building scalable infrastructure for batch processing (e.g., Spark, Hadoop) and stream processing (e.g., Kafka, Kinesis) for large volumes of data   Developer Toolset: Proficiency in programming languages for data engineering (i.e. Python and SQL) applied in conjunction with SDLC principles and developer practices (e.g. code/data version control, containerization, CI/CD, IaC, automated testing, monitoring/alerting).Data Modeling and Architecture:')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('Data Engineer looking to work with python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
