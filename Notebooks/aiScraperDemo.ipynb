{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements:\n",
    "langchain <br>\n",
    "langchain_ollama <br>\n",
    "selenium <br>\n",
    "beaufifulsoup4 <br>\n",
    "lxml <br>\n",
    "html5lib <br>\n",
    "python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(website):\n",
    "    print(\"Launching chrome browser...\")\n",
    "\n",
    "    chrome_driver_path = '../utils/chromedriver'\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "\n",
    "    try:\n",
    "        driver.get(website)\n",
    "        print(\"Page loaded...\")\n",
    "        html = driver.page_source\n",
    "\n",
    "        return html\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def extract_body_content(html_content):\n",
    "    soup = BeautifulSoup(html_content,\"html.parser\")\n",
    "    body_content = soup.body\n",
    "\n",
    "    if body_content:\n",
    "        print(\"Content extracted...\")\n",
    "        return str(body_content)\n",
    "    \n",
    "    print(\"Unable to collect content\")\n",
    "    \n",
    "def clean_body_content(body_content):\n",
    "    soup = BeautifulSoup(body_content,\"html.parser\")\n",
    "\n",
    "    for script_or_style in soup([\"script\",\"style\"]):\n",
    "        script_or_style.extract()\n",
    "\n",
    "    cleaned_content = soup.get_text(separator='\\n')\n",
    "    cleaned_content = \"\\n\".join(line.strip() for line in cleaned_content.splitlines() if line.strip())\n",
    "\n",
    "    print(\"Content cleaned...\")\n",
    "    return cleaned_content\n",
    "\n",
    "def split_dom_content(dom_content,max_length=6000):\n",
    "    return [\n",
    "        dom_content[i:i+max_length] for i in range(0,len(dom_content),max_length)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once Ollama is downloaded just do a 'ollama pull 'model-name'' to pull and be able to utilize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import re\n",
    "\n",
    "model = OllamaLLM(model='llama3')\n",
    "\n",
    "@dataclass\n",
    "class JobData:\n",
    "    title: str\n",
    "    company: str\n",
    "    salary: str\n",
    "    location: str\n",
    "    description: str\n",
    "\n",
    "# Updated template\n",
    "template = (\n",
    "    \"You are tasked with extracting specific information from the following text content: {dom_content}. \"\n",
    "    \"Please follow these instructions carefully:\\n\\n\"\n",
    "    \"1. **Extract Information:** Only extract the information that directly matches the parse description: {parse_description}.\\n\"\n",
    "    \"2. **Output Format:** Use the following JSON format to present your response:\\n\"\n",
    "    \"   [\\n\"\n",
    "    \"   {{\\n\"\n",
    "    \"       \\\"title\\\": \\\"<job title>\\\",\\n\"\n",
    "    \"       \\\"company\\\": \\\"<company name>\\\",\\n\"\n",
    "    \"       \\\"joblink\\\": \\\"<job link>\\\",\\n\"\n",
    "    \"       \\\"location\\\": \\\"<job location>\\\",\\n\"\n",
    "    \"       \\\"description\\\": \\\"<job description>\\\",\\n\"\n",
    "    \"   }}\\n\"\n",
    "    \"   ]\\n\"\n",
    "    \"4. **Misssing Information:** If there is any information for each job that is not mentioned fill that section with 'na'.\\n\"\n",
    "    \"5. **No Extra Content:** Do not include any additional text, notes, comments, or explanations in your response.\\n\"\n",
    "    \"6. **No content leading or following data:** Do not include any reponses before and after the data in its outputted format.\\n\"\n",
    "    \"6. **Empty Response:** If no information matches the description, return an empty JSON array: `[]`.\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_with_ollama(dom_chunks,parse_description):\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model\n",
    "\n",
    "    parsed_results = []\n",
    "\n",
    "    for i,chunk in enumerate(dom_chunks,start=1):\n",
    "        response = chain.invoke({\"dom_content\":chunk, \"parse_description\":parse_description})\n",
    "        print(f\"Parsed batch {i} of {len(dom_chunks)}\")\n",
    "\n",
    "        json_match = re.search(r\"(\\[.*\\])\", response, re.DOTALL)\n",
    "\n",
    "        try:\n",
    "            # Attempt to parse the response as JSON\n",
    "            if json_match:\n",
    "                for job in json.loads(json_match.group(1)):\n",
    "                    parsed_results.append(\n",
    "                        JobData(\n",
    "                            title=job.get(\"title\", \"\"),\n",
    "                            company=job.get(\"company\", \"\"),\n",
    "                            salary=job.get(\"salary\", \"Not mentioned\"),\n",
    "                            location=job.get(\"location\", \"\"),\n",
    "                            description=job.get(\"description\", \"\")\n",
    "                        )\n",
    "                    )\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "\n",
    "    return parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://careers.smartrecruiters.com/WesternDigital'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make this work you have to download the chrome driver and also run it in terminal 'pwd'/chromedriver and then when it pops up with a warning you open it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching chrome browser...\n",
      "Page loaded...\n",
      "Content extracted...\n",
      "Content cleaned...\n"
     ]
    }
   ],
   "source": [
    "result = scrape_website(url)\n",
    "body_content = extract_body_content(result)\n",
    "cleaned_content = clean_body_content(body_content)\n",
    "dom_chunks = split_dom_content(cleaned_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed batch 1 of 2\n",
      "Error parsing response: Expecting property name enclosed in double quotes: line 5 column 45 (char 139)\n",
      "Parsed batch 2 of 2\n"
     ]
    }
   ],
   "source": [
    "res = parse_with_ollama(dom_chunks,'Extract job information from all posted jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JobData(title='Quality Assurance Engineering', company='', salary='Not mentioned', location='na', description='na')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
