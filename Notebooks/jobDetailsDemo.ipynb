{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"../pinecone/data/db.db\"\n",
    "table_name = \"job_data\"\n",
    "\n",
    "conn = sqlite3.connect(db_name)\n",
    "\n",
    "# Dump the SQL query into a DataFrame\n",
    "df = pd.read_sql_query(f\"\"\"\n",
    "    SELECT jobLink, jobTitle, jobCompany, minSalary, maxSalary, jobDetails, jobLocation, pullDate\n",
    "    FROM {table_name}\n",
    "\"\"\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"../pinecone/data/db.db\"\n",
    "table_name = \"description_data\"\n",
    "\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"../pinecone/data/db.db\"\n",
    "table_name = \"ai_desc_data\"\n",
    "\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Dump the SQL query into a DataFrame\n",
    "df = pd.read_sql_query(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {table_name}\n",
    "\"\"\", conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_key            936e240b1f52062d0a59f36ddb9583341db1c680e11876...\n",
       "employment_type                                               Remote\n",
       "is_remote                                                          1\n",
       "yrs_exp                                                             \n",
       "job_desc           In Games Product:You’ll take ownership and inc...\n",
       "requirements       [\"7+ years in software development, with exper...\n",
       "company_desc       Netflix is a unique culture and environment.We...\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Requirement understanding and gathering\", \"Design and develop data pipelines for new module\", \"Unit testing and help UAT team for any issues\", \"Upload all the deliverables in Git and help prod team to deploy the code in prod\", \"Design and implement robust data transformation pipelines using pyspark\", \"Develop and maintain a scalable data pipeline architecture that supports a wide variety of data sources and business use cases.\", \"Collaborate with data engineers and business stakeholders to define requirements for data transformations and models.\", \"Lead best practices for pipeline development including modularity testing version control and continuous integration (CI/CD).\", \"Optimize data pipeline models for performance and scalability in a cloud-based data warehouse environment (AWS S3 Redshift).\", \"Ensure data quality and governance through well-defined data transformation processes testing frameworks and documentation.\", \"Troubleshoot and resolve issues related to data pipelines transformations.\", \"Mentor and train team members on data pipeline best practices encouraging a data-driven culture across the organization.\"]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['requirements'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Description:Resources will assist clients with rack, stack and installation of key data center equipment.They will help troubleshoot common issues, work through various tickets and act as a level 1 administrator for any data center issues.Do mechanical assembly/disassembly and install heavy GPU trays into systemsBuild up prototype open board systems on the benchtop and debugging issues reported by users.Triage and debug systems and get systems to pass base line diagnostics.Requirements:Strong data center experience with rack and stack,Minimum of 5 years on-prem large scale data center experience supporting the Data Center equipment and/or infrastructure (Power, Space, Cooling, Equipment)Strong cabling skills, cable management and dressingStrong NW troubleshooting experience, ideally with Supermicro Servers, Infiniband Fabric and Mellanox, Arista HardwareStrong attention to detail, independent and out of box thinkingSolid skills in UNIX (Ubuntu or RedHat) administration and knowledge of commands including logging into the server’s to monitor for disk failures, debug systems, etcBreak fix server expertise including mechanical assembly/disassembly, installing heavy GPU trays, changing system configs and building up prototypeJob Type: Full-timePay: $40.00 - $65.00 per hourBenefits:401(k)Dental insuranceHealth insurancePaid time offVision insuranceSchedule:Day shiftExperience:Data center: 2 years (Required)Cabling: 2 years (Required)Ability to Relocate:San Jose, CA 95110: Relocate before starting work (Required)Work Location: In person'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_num = 17\n",
    "cur_details = df['jobDetails'].iloc[job_num]\n",
    "cur_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Type: Full-time\n",
      "Is Remote: False\n",
      "Yrs Exp: Not specified\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = text.strip()  # Trim leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "def extract_job_type(text):\n",
    "    job_types = [\"full[- ]?time\", \"part[- ]?time\", \"contract\", \"temporary\", \"internship\", \"freelance\"]\n",
    "    pattern = re.compile(\"|\".join(job_types), re.IGNORECASE)\n",
    "    match = pattern.search(text)\n",
    "    return match.group(0).capitalize() if match else \"Not specified\"\n",
    "\n",
    "def is_remote(text):\n",
    "    remote_keywords = [\"remote\", \"work from home\", \"telecommute\", \"virtual\"]\n",
    "    pattern = re.compile(\"|\".join(remote_keywords), re.IGNORECASE)\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "def extract_max_years_experience(job_details):\n",
    "    \"\"\"\n",
    "    Extracts the maximum years of experience from a job description.\n",
    "\n",
    "    Parameters:\n",
    "    job_details (str): The job details text blob.\n",
    "\n",
    "    Returns:\n",
    "    str: Maximum years of experience or 'Not specified' if not found.\n",
    "    \"\"\"\n",
    "    # Define regex patterns to capture years of experience\n",
    "    patterns = [\n",
    "        r'(\\d{1,2})\\+?\\s*(?:years|yrs)\\s*of\\s*experience',  # e.g., '5 years of experience', '3+ years'\n",
    "        r'(\\d{1,2})-(\\d{1,2})\\s*(?:years|yrs)',             # e.g., '3-5 years'\n",
    "        r'at least\\s*(\\d{1,2})\\s*(?:years|yrs)'             # e.g., 'at least 2 years'\n",
    "    ]\n",
    "    \n",
    "    # List to collect all found years of experience\n",
    "    years = []\n",
    "\n",
    "    # Loop through patterns and find all matches\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, job_details, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            # If it's a tuple (from a range), take the max of the range\n",
    "            if isinstance(match, tuple):\n",
    "                years.extend(map(int, match))\n",
    "            else:\n",
    "                years.append(int(match))\n",
    "\n",
    "    # Return the max years found or 'Not specified' if the list is empty\n",
    "    return max(years) if years else 'Not specified'\n",
    "\n",
    "clean_details = preprocess_text(cur_details)\n",
    "job_type = extract_job_type(clean_details)\n",
    "is_remote = is_remote(clean_details)\n",
    "yrs_exp = extract_max_years_experience(clean_details)\n",
    "\n",
    "print(\"Job Type:\", job_type)\n",
    "print(\"Is Remote:\", is_remote)\n",
    "print(\"Yrs Exp:\", yrs_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "import json\n",
    "\n",
    "def create_prompt(job_details):\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant that extracts structured information from job postings. Below is a job posting from Indeed:\n",
    "\n",
    "    {job_details}\n",
    "\n",
    "    Extract the following information in JSON format:\n",
    "    - \"job_description\": The full text of the job description, including all responsibilities and skills needed as stated.\n",
    "    - \"requirements\": A list of job requirements exactly as listed in the posting.\n",
    "    - \"employment_type\": A string with either full-time or contract if the job is full-time or contract.\n",
    "    - \"experience\": A string of the range of amount of years required for this job, return None if job posting does not mention.\n",
    "    - \"remote\": A boolean, 1 if the job is remote, 0 if the job is not remote.\n",
    "    - \"company_description\": The full text of the company description (if available).\n",
    "\n",
    "    Maintain the wording and details as much as possible as they are presented. You can summarize lightly.\n",
    "\n",
    "    Return the output in the following JSON format:\n",
    "    {{\n",
    "        \"job_description\": \"...\",\n",
    "        \"requirements\": [\"...\", \"...\"],\n",
    "        \"employment_type\": \"...\",\n",
    "        \"experience\": \"...\",\n",
    "        \"remote\": \"...\",\n",
    "        \"company_description\": \"...\"\n",
    "    }}\n",
    "\n",
    "    Do not return anything else but the data in JSON format.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def ask_ollama(prompt):\n",
    "    model = OllamaLLM(model=\"llama3.2\")\n",
    "    response = model.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "def parse_llm_response(response):\n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def extract_job_details(job_details):\n",
    "    # Preprocess the job details\n",
    "    job_details = preprocess_text(job_details)\n",
    "    \n",
    "    # Create the prompt for Ollama\n",
    "    prompt = create_prompt(job_details)\n",
    "    \n",
    "    # Ask Ollama to extract the information\n",
    "    response = ask_ollama(prompt)\n",
    "    \n",
    "    # Parse the response into a dictionary\n",
    "    structured_data = parse_llm_response(response)\n",
    "    \n",
    "    return structured_data\n",
    "\n",
    "extracted_sections = extract_job_details(clean_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Description: Resources will assist clients with rack, stack and installation of key data center equipment.They will help troubleshoot common issues, work through various tickets and act as a level 1 administrator for any data center issues.Do mechanical assembly/disassembly and install heavy GPU trays into systemsBuild up prototype open board systems on the benchtop and debugging issues reported by users.Triage and debug systems and get systems to pass base line diagnostics.\n",
      "********************\n",
      "requirements: ['Strong data center experience with rack and stack', 'Minimum of 5 years on-prem large scale data center experience supporting the Data Center equipment and/or infrastructure (Power, Space, Cooling, Equipment)', 'Strong cabling skills, cable management and dressing', 'Strong NW troubleshooting experience, ideally with Supermicro Servers, Infiniband Fabric and Mellanox, Arista Hardware', 'Strong attention to detail, independent and out of box thinking', 'Solid skills in UNIX (Ubuntu or RedHat) administration and knowledge of commands including logging into the server’s to monitor for disk failures, debug systems, etc', 'Break fix server expertise including mechanical assembly/disassembly, installing heavy GPU trays, changing system configs and building up prototype']\n",
      "********************\n",
      "exmployment Type: Full-time\n",
      "********************\n",
      "Experience: 2 years\n",
      "********************\n",
      "remote: False\n",
      "********************\n",
      "Company Description: \n"
     ]
    }
   ],
   "source": [
    "print(\"Job Description:\",extracted_sections.get(\"job_description\",\"\"))\n",
    "print(\"*\"*20)\n",
    "print(\"requirements:\",extracted_sections.get(\"requirements\",\"\"))\n",
    "print(\"*\"*20)\n",
    "print(\"exmployment Type:\",extracted_sections.get(\"employment_type\",\"\"))\n",
    "print(\"*\"*20)\n",
    "print(\"Experience:\",extracted_sections.get(\"experience\",\"\"))\n",
    "print(\"*\"*20)\n",
    "print(\"remote:\",extracted_sections.get(\"remote\",\"\"))\n",
    "print(\"*\"*20)\n",
    "print(\"Company Description:\",extracted_sections.get(\"company_description\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
